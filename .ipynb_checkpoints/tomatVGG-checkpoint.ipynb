{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klasifikasi = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "klasifikasi.add(ZeroPadding2D((1,1),input_shape=(64, 64, 3)))\n",
    "klasifikasi.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "klasifikasi.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "klasifikasi.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "klasifikasi.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "klasifikasi.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "klasifikasi.add(ZeroPadding2D((1,1)))\n",
    "klasifikasi.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "klasifikasi.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "klasifikasi.add(Flatten())\n",
    "klasifikasi.add(Dense(4096, activation='relu'))\n",
    "klasifikasi.add(Dropout(0.5))\n",
    "klasifikasi.add(Dense(4096, activation='relu'))\n",
    "klasifikasi.add(Dropout(0.5))\n",
    "klasifikasi.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompile cnn\n",
    "klasifikasi.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
    "print(\"Compiling Initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2 -fitting the cnn to images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "        '../tomat/segment/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        '../tomat/segment/testing_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datanya = klasifikasi.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=8917,\n",
    "        epochs=25,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=3923)\n",
    "print(\"Compiling Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat prediksi\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('sp.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = klasifikasi.predict(test_image)\n",
    "train_set.class_indices\n",
    "\n",
    "print(datanya.history.keys())\n",
    "print(datanya.history['acc'])\n",
    "print(datanya.history['val_acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(datanya.history['acc'])\n",
    "plt.plot(datanya.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# history untuk loss\n",
    "plt.plot(datanya.history['loss'])\n",
    "plt.plot(datanya.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpan ke json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model ke JSON\n",
    "model_json = klasifikasi.to_json()\n",
    "with open(\"hasil/tomatVgg_classifier.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "klasifikasi.save_weights(\"hasil/tomatVgg_classifier.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "json_file = open('hasil/tomatVgg_classifier.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_classifier = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_classifier.load_weights(\"hasil/tomatVgg_classifier.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
